{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "textblock1",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# SNAPI Overview\n",
    "\n",
    "SNAPI (Supernova API) is a Python package designed to simplify import and manipulation of transient data from a variety of sources and modalities. SNAPI also provides an API for light curve fitting, and an interface for generating consistent and high-quality data plots.\n",
    "\n",
    "Here, we will go through a few examples of how SNAPI can be used to simplify transient workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c5d6d7",
   "metadata": {},
   "source": [
    "## Example 1: Aggregating and displaying information about 2023ixf\n",
    "In SNAPI, information about a transient is stored as a Transient object. Transient objects have the following attributes:\n",
    "* 'id': the transient identifier. Defaults to a TNS/IAU name if provided, but can also be an instrument-specific name.\n",
    "* 'coordinates': an astropy SkyCoord representing the location of the transient in the sky. Assumes stationarity (aka. not NEUs or other moving objects).\n",
    "* 'redshift': the redshift of the transient, if available. Currently only queries spectroscopic redshifts.\n",
    "* 'internal_names': a set of other names that represent the same transient. For example, can contain ZTF or ANTARES names. Queries of the transient will check all internal names.\n",
    "* 'photometry': a Photometry object containing all light curves associated with the transient.\n",
    "* 'spectroscopy': a Spectroscopy object containing all spectra associated with the transient.\n",
    "* 'spec_class': the spectroscopic classification of the transient, if available.\n",
    "\n",
    "In this example, we will show how to aggregate information about 2023ixf from multiple online databases from just its IAU name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb8ae06",
   "metadata": {},
   "source": [
    "First, let's create a Transient object for 2023ixf. This object will only have a non-empty 'id' field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "codeblock1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snapi import Transient\n",
    "\n",
    "ixf_transient = Transient(iid=\"2023ixf\")\n",
    "print(ixf_transient.id)\n",
    "print(ixf_transient.coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textblock2",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "Next, we will populate this Transient object from results of multiple queries to data brokers (stored as a QueryResult for each query). Currently, the following QueryAgent classes are implemented:\n",
    "* TNSQueryAgent: useful for retrieving coordinates, redshift, spectroscopic class, spectra, and alternate identifiers. Has limited photometry. Requires API keys in local environment.\n",
    "* ALeRCEQueryAgent: retrieves photometry, but requires a ZTF internal name to be in the Transient object. Therefore, I recommend querying TNS first if using an IAU identifier. Includes forced photometry if using custom alerce_client repository.\n",
    "* ANTARESQueryAgent: also retrieves photometry that SHOULD match ALeRCE's but without forced photometry. I've seen cases where they have not been identical. Also requires a ZTF- or ANT- internal name.\n",
    "* GHOSTQueryAgent: for host galaxy querying. Not yet integrated into the Transient object framework.\n",
    "\n",
    "QueryAgents in progress:\n",
    "* YSEQueryAgent: to retrieve information from the Young Supernova Experiment databases, which uses Pan-STARRS photometry.\n",
    "* ATLASQueryAgent: to retrieve photometry from ATLAS, a southern hemisphere telescope.\n",
    "\n",
    "To use a QueryAgent, we first instantiate a QueryAgent object, and then run its query_transient() function with the transient object as input. This will automatically try:\n",
    "(1) Querying the 'id' and each name in 'internal_names' sequentially for matches.\n",
    "(2) Doing a cone search based on 'coordinates', if not empty. Only implemented for TNS and ANTARES.\n",
    "\n",
    "The output of query_transient() is a list of QueryResults and a boolean stating if a match was found. We can then convert each QueryResult object to a dictionary using to_dict(), and then save that dictionary's contents to the transient by using the transient's \"ingest_query_info()\" function. This will automatically handle:\n",
    "* Merging light curves from the same filter/instrument without repeats.\n",
    "* Only overriding transient attributes if they were previously null.\n",
    "* Adding any yet undiscovered internal names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "codeblock2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snapi.query_agents import TNSQueryAgent, ALeRCEQueryAgent, ANTARESQueryAgent\n",
    "\n",
    "from snapi import Transient, Photometry\n",
    "\n",
    "\n",
    "tns_query_agent = TNSQueryAgent()\n",
    "alerce_query_agent = ALeRCEQueryAgent()\n",
    "antares_agent = ANTARESQueryAgent()\n",
    "\n",
    "for agent in [tns_query_agent, alerce_query_agent]:\n",
    "    ixf_transient.photometry = Photometry()\n",
    "    query_results, _ = agent.query_transient(ixf_transient)\n",
    "    for query_result in query_results:\n",
    "        ixf_transient.ingest_query_info(query_result.to_dict())\n",
    "    print(ixf_transient.internal_names)\n",
    "\n",
    "\n",
    "# ixf_transient = Transient.load(\"data/ixf_transient.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f593f22",
   "metadata": {},
   "source": [
    "Let's now see what information is saved to the 2023ixf Transient object now. To check the photometry specifically, we can look at the transient.photometry.light_curves attribute, each which has a 'filter' attribute summarizing the instrument and band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "codeblock3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all unique filters\n",
    "print(len(ixf_transient.photometry))  # how many light curves?\n",
    "for lc in ixf_transient.photometry.light_curves:\n",
    "    print(lc.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9be410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all extracted transient-level information\n",
    "print(ixf_transient.coordinates)\n",
    "print(ixf_transient.redshift)\n",
    "print(ixf_transient.spec_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09d18d1",
   "metadata": {},
   "source": [
    "Now, we go into plotting. Plotting aesthetics is controlled by the Formatter class, where you can set properties such as:\n",
    "* Line-specific parameters: 'linewidth', 'edge_colors'\n",
    "* Marker-specific parameters: 'markersize', 'marker_styles', 'face_colors', 'edge_colors'\n",
    "* Non-detection-specific parameters: 'nondetect_alpha', 'nondetect_marker_size', 'nondetect_size'\n",
    "* Labels: 'fontname'\n",
    "\n",
    "These can be set as keywords in the Formatter() initialization. In addition, there's two main functions that help generate clean plots:\n",
    "* make_plot_pretty(ax): this automatically resizes plot labels, changes fonts, modifies grid lines, etc. This ensures all plots look cohesive and paper-ready. WARNING: not optimized yet for figures with multiple subplots.\n",
    "* add_legend(ax, ncols): this adds a legend to the plot and includes all axes objects added with the \"label\" keyword. \"ncols\" determines how many columns the legend is split into. Automatically places legend outside of the axis grid itself for better clarity.\n",
    "\n",
    "Many classes in SNAPI inherit from the Plottable abstract class, which means they can be plotted using .plot(). This includes the Photometry, Spectroscopy, LightCurve, and Spectrum classes. Let's see how we can plot 2023ixf's photometry using Formatter() and .plot():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26dc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all photometry\n",
    "import matplotlib.pyplot as plt\n",
    "from snapi import Formatter\n",
    "\n",
    "formatter = Formatter()  # initialize formatter\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ixf_transient.photometry.plot(ax, formatter=formatter)  # the .plot() function\n",
    "formatter.make_plot_pretty(ax)  # make the plot pretty\n",
    "formatter.add_legend(ax, ncols=2)  # add a legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b660c132",
   "metadata": {},
   "source": [
    "Looks pretty good! Now let's see the same plot in flux space.\n",
    "\n",
    "SNAPI photometry is extremely useful in that upon creation or modification, it will automatically fill in fluxes or magnitudes if one is provided along with zeropoints. That means that, for example, we can import only sets of magnitudes and zeropoints and automatically be able to plot fluxes. There is also the option use calibrated fluxes using the LightCurve's .calibrate() function, but we will not use that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ab3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also plot in flux space\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ixf_transient.photometry.plot(ax, mags=False)\n",
    "formatter.add_legend(ax, ncols=2)\n",
    "formatter.make_plot_pretty(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c232026f",
   "metadata": {},
   "source": [
    "Because a Photometry object consists of a collection of LightCurve objects, we can instead plot each LightCurve individually by calling \"lc.plot()\" for each lc in transient.photometry.light_curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e43ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snapi import Formatter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# can also plot each LC individually\n",
    "formatter = Formatter()\n",
    "fig, axes = plt.subplots(4, 2, figsize=(10, 14))\n",
    "for i, lc in enumerate(ixf_transient.photometry.light_curves):\n",
    "    print(lc.filter)\n",
    "    print(lc.mag_errors)\n",
    "    ax = axes.flatten()[i]\n",
    "    lc.plot(ax, formatter)\n",
    "    ax.legend(loc=\"best\")\n",
    "    # formatter.make_plot_pretty(ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287e9f74",
   "metadata": {},
   "source": [
    "Now we can move on to spectra. Through TNS, we automatically imported a series of spectra for 2023ixf. Let's plot these in a few different ways: first overlaying all spectra, then by introducing a vertical offset. The vertical offsets are automatically calculated to prevent any line overlaps (which could look strange for very noisy spectra).\n",
    "\n",
    "In the second example, we also overlay spectral lines on the spectra. While we overlay \"He I\", there is an entire collection of lines we can overlay which can be found in the \"src/constants/ion_lines.py\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e4bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from snapi import Formatter\n",
    "\n",
    "spectra = ixf_transient.spectroscopy\n",
    "formatter = Formatter(linewidth=1)  # good for spectra\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "spectra.plot(ax, formatter)\n",
    "formatter.make_plot_pretty(ax)\n",
    "formatter.add_legend(ax, ncols=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c946a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from snapi import Formatter\n",
    "\n",
    "spectra = ixf_transient.spectroscopy\n",
    "formatter = Formatter(linewidth=1)\n",
    "fig, ax = plt.subplots(figsize=(8, 16))\n",
    "spectra.plot(ax, formatter, vertical_offsets=True, overlay_lines=[\"He I\"])\n",
    "formatter.make_plot_pretty(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af5f45",
   "metadata": {},
   "source": [
    "Finally, we should save this transient so we can retrieve information later without re-querying. Thankfully, SNAPI has an extremely simple save/load functionality based around HDF5 files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4092385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ixf_transient_path = os.path.abspath(\"data/ixf_transient.hdf5\")\n",
    "ixf_transient.save(ixf_transient_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274125c8",
   "metadata": {},
   "source": [
    "## Example 2: Querying by RA/dec\n",
    "Previously, I briefly mentioned that one can query transient information using coordinates instead of name. Whereas the previous example queried 2023ixf by IAU name, here we use RA/DEC to cross-match a dataset of DECAM DDF \"likely-real\" candidates: https://arxiv.org/abs/2211.09202 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda77cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DECAM data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "decam_fn = \"data/candidates.dat\"\n",
    "decam_df = pd.read_table(\n",
    "    decam_fn,\n",
    "    sep=r\"\\s+\",\n",
    "    comment=\"#\",\n",
    "    names=[\"field\", \"id\", \"ra\", \"dec\", \"n_obs\", \"mean_rb\"],\n",
    "    usecols=np.arange(6),\n",
    ")\n",
    "print(decam_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee03d8",
   "metadata": {},
   "source": [
    "There are two sets of fields in the DECAM deep-drilling fields: 3 fields that overlap with COSMOS (declination ~1-4 degrees), and 2 fields at lower declination (-45 -> -42 deg). Let's display them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db672733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# plot COSMOS ra/dec distribution\n",
    "cosmos_ddf = decam_df[decam_df[\"field\"] == \"COSMOS\"]\n",
    "l = ax[0].scatter(\n",
    "    cosmos_ddf[\"ra\"], cosmos_ddf[\"dec\"], c=cosmos_ddf[\"mean_rb\"], cmap=\"viridis\", vmax=1.0, s=10\n",
    ")\n",
    "ax[0].set_title(\"COSMOS fields\")\n",
    "\n",
    "# plot non-COSMOS fields\n",
    "non_cosmos_ddf = decam_df[decam_df[\"field\"] != \"COSMOS\"]\n",
    "l2 = ax[1].scatter(\n",
    "    non_cosmos_ddf[\"ra\"], non_cosmos_ddf[\"dec\"], c=non_cosmos_ddf[\"mean_rb\"], cmap=\"viridis\", vmax=1.0, s=10\n",
    ")\n",
    "ax[1].set_title(\"Non-COSMOS fields\")\n",
    "fig.colorbar(label=\"Mean real-bogus score\", mappable=l2)\n",
    "\n",
    "ax[0].set_xlabel(\"RA\")\n",
    "ax[1].set_xlabel(\"RA\")\n",
    "ax[0].set_ylabel(\"Dec\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef1d7d2",
   "metadata": {},
   "source": [
    "As we can see, all events in this dataset have a mean real-bogus score above 0.4, which is the \"probably-real\" threshhold according to the paper, so we keep all events for cross-matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ead8d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now colorbar by number of observations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# plot COSMOS ra/dec distribution\n",
    "cosmos_ddf = decam_df[decam_df[\"field\"] == \"COSMOS\"]\n",
    "l = ax[0].scatter(cosmos_ddf[\"ra\"], cosmos_ddf[\"dec\"], c=cosmos_ddf[\"n_obs\"], cmap=\"viridis\", vmax=100, s=10)\n",
    "ax[0].set_title(\"COSMOS fields\")\n",
    "\n",
    "# plot non-COSMOS fields\n",
    "non_cosmos_ddf = decam_df[decam_df[\"field\"] != \"COSMOS\"]\n",
    "l2 = ax[1].scatter(\n",
    "    non_cosmos_ddf[\"ra\"], non_cosmos_ddf[\"dec\"], c=non_cosmos_ddf[\"n_obs\"], cmap=\"viridis\", vmax=100, s=10\n",
    ")\n",
    "ax[1].set_title(\"Non-COSMOS fields\")\n",
    "fig.colorbar(label=\"Number of observations\", mappable=l2)\n",
    "\n",
    "ax[0].set_xlabel(\"RA\")\n",
    "ax[1].set_xlabel(\"RA\")\n",
    "ax[0].set_ylabel(\"Dec\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181b7343",
   "metadata": {},
   "source": [
    "Many events (those in yellow) have over 100 observations; they are probably AGN or very long-duration TDEs/SNe.\n",
    "\n",
    "Because northern sky telescopes like ZTF and Pan-STARRS have a minimum declination > ~-30 degrees, we expect potential TNS cross-matches within only the COSMOS fields. Let's use SNAPI to make this cross-matching simple. The series of steps for each entry are:\n",
    "\n",
    "(1) Create a Transient object with the DECam identifier (NOT IAU) and the RA and declination values. Because these are floats in degree, we need to add units using astropy before initialization.\n",
    "\n",
    "(2) Because we don't have a ZTF or IAU identifier, we won't be able to query by name from TNS or ALeRCE. However, we can use the exact same command \"query_transient()\" and SNAPI will automatically try a cone search. NOTE: here we use the \"local=True\" keyword. This, instead of querying TNS directly, consults a local CSV containing all TNS entries as of time of creation. While no photometry or spectroscopy are saved locally, this is the much faster option for a loop involving thousands of TNS queries, which we are doing here.\n",
    "\n",
    "(3) If a match was found, then transient's \"id\" field will automatically be replaced by the IAU name, and the DECam identifier will be moved to \"internal_names\". Therefore, we check whether the internal_names field is non-empty and if so, add the transient to our collection of successfully cross-matched objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f77b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from snapi import Transient\n",
    "from snapi.query_agents import TNSQueryAgent\n",
    "\n",
    "tns_query_agent = TNSQueryAgent()\n",
    "cross_matched_transients = set()\n",
    "\n",
    "\n",
    "for i, row in decam_df.iterrows():\n",
    "    if i % 500 == 0:\n",
    "        print(f\"Processing transient {i}/{len(decam_df)}\")\n",
    "    decam_transient = Transient(\n",
    "        iid=row[\"id\"],\n",
    "        ra=row[\"ra\"] * u.deg,  # pylint: disable=no-member\n",
    "        dec=row[\"dec\"] * u.deg,  # pylint: disable=no-member\n",
    "    )\n",
    "\n",
    "    # query TNS\n",
    "    query_results, _ = tns_query_agent.query_transient(decam_transient, local=True)\n",
    "    for query_result in query_results:\n",
    "        decam_transient.ingest_query_info(query_result.to_dict())\n",
    "\n",
    "    # check if IAU name found\n",
    "    if decam_transient.internal_names:  # check if non-empty\n",
    "        print(f\"Matched {row['id']} with TNS object {decam_transient.spec_class} {decam_transient.id}\")\n",
    "        cross_matched_transients.add(decam_transient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0100083a",
   "metadata": {},
   "source": [
    "We see we've successfully crossmatched a handful of DDF events with TNS! Let's save the Transient objects so we don't have to rerun that loop every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f255ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save matching transients\n",
    "for transient in cross_matched_transients:\n",
    "    transient.save(f\"data/ddf_transient_{transient.id}.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25f658",
   "metadata": {},
   "source": [
    "Now that we've reduced the dataset down to a small number, let's run a full query loop on each event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222912c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from snapi.query_agents import TNSQueryAgent, ANTARESQueryAgent\n",
    "from snapi import Transient, Formatter\n",
    "\n",
    "tns_agent = TNSQueryAgent()\n",
    "antares_agent = ANTARESQueryAgent()\n",
    "formatter = Formatter()\n",
    "\n",
    "# ensure we can load the transients\n",
    "for f in glob.glob(\"data/ddf_transient_*.hdf5\"):\n",
    "    transient = Transient.load(f)\n",
    "\n",
    "    # small internal names fix\n",
    "    internal_names = set(transient.internal_names)\n",
    "    if \"nan\" in transient.internal_names:\n",
    "        internal_names.remove(\"nan\")\n",
    "    transient.internal_names = internal_names\n",
    "\n",
    "    for agent in [tns_agent, antares_agent]:\n",
    "        query_results, _ = agent.query_transient(transient)\n",
    "        for query_result in query_results:\n",
    "            transient.ingest_query_info(query_result.to_dict())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    transient.photometry.plot(ax)\n",
    "    ax.set_title(f\"{transient.id} ({\", \".join(transient.internal_names)})\")\n",
    "    formatter.make_plot_pretty(ax)\n",
    "    formatter.add_legend(ax, ncols=2)\n",
    "    plt.show()\n",
    "\n",
    "    # now re-save\n",
    "    transient.save(f\"data/ddf_transient2_{transient.id}.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba60429",
   "metadata": {},
   "source": [
    "2019tzk looks like an AGN, and has significant ZTF data. Let's overlay our DECAM photometry by adding it to the Transient object and re-plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c30dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "from astropy.timeseries import TimeSeries\n",
    "from astropy import units as u\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from snapi import LightCurve, Filter, Formatter, Transient\n",
    "import os\n",
    "\n",
    "transient_2019tzk = Transient.load(\"data/ddf_transient2_2019tzk.hdf5\")\n",
    "formatter = Formatter()\n",
    "\n",
    "# photometry file for DECam\n",
    "observations_df = pd.read_csv(\n",
    "    \"data/DC21fyx.csv\",\n",
    "    usecols=[4, 5, 6, 7, 8],\n",
    "    header=0,\n",
    ")\n",
    "print(observations_df.head())\n",
    "\n",
    "for band in np.unique(observations_df[\"filter\"]):  # we save each band separately as a LightCurve object\n",
    "    band_df = observations_df[observations_df[\"filter\"] == band]\n",
    "    filt = Filter(  # first we create a Filter object for each DECam filter\n",
    "        instrument=\"DECam\",\n",
    "        band=band,\n",
    "        center=np.nan * u.AA,\n",
    "    )\n",
    "    time_mjds = Time(band_df[\"meanmjd\"].values, format=\"mjd\")\n",
    "    lc = LightCurve(\n",
    "        times=time_mjds,\n",
    "        fluxes=band_df[\"flux\"].values,\n",
    "        flux_errs=band_df[\"fluxerr\"].values,\n",
    "        zpts=band_df[\"magzp\"].values,\n",
    "        filt=filt,  # we pass the Filter object to the LightCurve object\n",
    "    )\n",
    "    transient_2019tzk.photometry.add_lightcurve(lc)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "transient_2019tzk.photometry.plot(ax)\n",
    "ax.set_title(\"2019tzk (with DECam data)\")\n",
    "formatter.make_plot_pretty(ax)\n",
    "formatter.add_legend(ax, ncols=2)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total observations: {len(transient_2019tzk.photometry.detections)}\")\n",
    "\n",
    "\n",
    "transient_2019tzk_path = os.path.abspath(\"data/ddf_transientdecam_2019tzk.hdf5\")\n",
    "transient_2019tzk.save(transient_2019tzk_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b827f6a",
   "metadata": {},
   "source": [
    "We see here that the DECam and ZTF data align very well, capturing the same stochastic behavior of the AGN. However, we note that above, there were TWO DECam events that mapped to 2019tzk, the other being DC21crhk. Let's add that data in as well. Because this light curve has the same filter as the previous DECam light curve, it will actually merge observations with the existing LightCurve for that filter, instead of creating a new LightCurve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "from astropy import units as u\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from snapi import LightCurve, Filter, Formatter, Transient\n",
    "import os\n",
    "\n",
    "transient_2019tzk = Transient.load(\"data/ddf_transientdecam_2019tzk.hdf5\")\n",
    "formatter = Formatter()\n",
    "\n",
    "observations_df = pd.read_table(\n",
    "    \"data/DC21crhk.csv\",\n",
    "    usecols=[5, 6, 7, 8],\n",
    "    names=[\"meanmjd\", \"filter\", \"mag\", \"magerr\"],\n",
    "    sep=r\"\\s+\",\n",
    ")\n",
    "\n",
    "for band in np.unique(observations_df[\"filter\"]):\n",
    "    band_df = observations_df[observations_df[\"filter\"] == band]\n",
    "    filt = Filter(\n",
    "        instrument=\"DECam\",\n",
    "        band=band,\n",
    "        center=np.nan * u.AA,\n",
    "    )\n",
    "    time_mjds = Time(band_df[\"meanmjd\"].values, format=\"mjd\")\n",
    "    lc = LightCurve(times=time_mjds, mags=band_df[\"mag\"].values, mag_errs=band_df[\"magerr\"].values, filt=filt)\n",
    "    transient_2019tzk.photometry.add_lightcurve(lc)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "transient_2019tzk.photometry.plot(ax)\n",
    "ax.set_title(\"2019tzk (with more DECam data)\")\n",
    "formatter.make_plot_pretty(ax)\n",
    "formatter.add_legend(ax, ncols=2)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total observations: {len(transient_2019tzk.photometry.detections)}\")\n",
    "transient_2019tzk_path = os.path.abspath(\"data/ddf_transientdecam_2019tzk.hdf5\")\n",
    "transient_2019tzk.save(transient_2019tzk_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523f4d61",
   "metadata": {},
   "source": [
    "Only 11 observations were added, so not much difference is noted!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8b3a7",
   "metadata": {},
   "source": [
    "## Example 3: Fitting Photometry using the Sampler class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b10615c",
   "metadata": {},
   "source": [
    "After importing and saving photometry, we would like to extract information from that photometry for downstream tasks. One way we can do so is by fitting the light curves in photometry to a specific model. In SNAPI, we accomplish this by defining a subclass of the Sampler class.\n",
    "\n",
    "The Sampler class actually inherits from scikit-learn's BaseEstimator class, which means it has the standard .fit()/.predict()/.score() framework we see in all scikit-learn classifiers and regressors. For the .fit() function, we provide data to fit, and the .predict() function gives us predicted fluxes/magnitudes for new inputs. For the samplers used in this demo, .score() returns the reduced chi-squared of the best fits. In addition, SNAPI's Sampler has custom-defined .fit_photometry() and .predict_photometry() functions, which allows us to directly feed in a Photometry object and return sets of fit parameters.\n",
    "\n",
    "Fit parameters are stored in a SamplingResult object. The main attributes are:\n",
    "\n",
    "* 'fit_parameters': pandas DataFrame containing equally-weighted posterior samples of each model parameter.\n",
    "\n",
    "* 'score': the median reduced chi-squared of all fits from 'fit_parameters'\n",
    "\n",
    "\n",
    "Like other SNAPI objects, SamplingResult objects can be saved/loaded using .save() and .load(), respectively. A SamplingResult can be linked to a Sampler using .load_result(), which will run the SamplingResult's load() function and assign it to the Sampler's \"result\" attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b018f8",
   "metadata": {},
   "source": [
    "Superphot+'s nested sampler is implemented as a subclass of Sampler, so we can integrate it seamlessly into our SNAPI framework. Let's test it out on 2023ixf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f63490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this example, we'll be using ZTF photometry from 2023ixf.\n",
    "from snapi import Transient\n",
    "import matplotlib.pyplot as plt\n",
    "from snapi import Formatter\n",
    "\n",
    "formatter = Formatter()\n",
    "ixf_transient = Transient.load(\"data/ixf_transient.hdf5\")\n",
    "ixf_photometry = ixf_transient.photometry\n",
    "ztf_photometry = ixf_photometry.filter({\"ZTF_g\", \"ZTF_r\"})  # filter for ZTF g and r bands\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ztf_photometry.plot(ax, formatter=formatter)\n",
    "formatter.make_plot_pretty(ax)\n",
    "formatter.add_legend(ax, ncols=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f480b5",
   "metadata": {},
   "source": [
    "Note that SNAPI's fit_photometry() and predict_photometry() functions will automatically phase and normalize the photometry. This means that one has to then rescale the fit by the peak flux (or magnitude) to arrive back at original amplitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8789d9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make sure to install Superphot+ from source\n",
    "from superphot_plus.samplers.dynesty_sampler import DynestySampler\n",
    "from superphot_plus.surveys.surveys import Survey\n",
    "import warnings\n",
    "\n",
    "from snapi import Photometry\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "priors = Survey.ZTF().priors\n",
    "\n",
    "dynesty_sampler = DynestySampler(priors, random_state=42)\n",
    "\n",
    "print(ztf_photometry.detections)\n",
    "dynesty_sampler.fit_photometry(ztf_photometry)\n",
    "s_result = dynesty_sampler.result\n",
    "print(s_result.score)\n",
    "print(s_result.fit_parameters.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b157958",
   "metadata": {},
   "source": [
    "Now, let's plot the fits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3d0eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from snapi import Formatter\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "formatter = Formatter()\n",
    "\n",
    "dynesty_sampler.plot_fit(ax=ax, formatter=formatter, photometry=ztf_photometry)  # plot fit\n",
    "ztf_photometry.plot(ax, formatter, mags=False)  # plot data\n",
    "\n",
    "ax.set_title(f\"{transient.id}: {dynesty_sampler.result.score:.2f}\")\n",
    "formatter.make_plot_pretty(ax)\n",
    "formatter.add_legend(ax, ncols=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2432d8",
   "metadata": {},
   "source": [
    "We can now fit and plot fitted transients in just a few lines!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ab9f9f",
   "metadata": {},
   "source": [
    "This is where the demo ends for now, but SNAPI is expected to gain many functionalities in the next few months. This includes:\n",
    "\n",
    "* Host galaxy querying and addition to transient information. Also includes incorporating host redshifts and displaying postage stamps.\n",
    "\n",
    "* Simple spectra reduction + pre-processing.\n",
    "\n",
    "* Conversion of photometry into arrays for machine learning applications.\n",
    "\n",
    "* Abstract class for Classifiers which also follow the scikit-learn BaseEstimator framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8157e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_markers": "\"\"\""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
